# Tavus Pipecat Quickstart

A complete, production-ready starter project for building conversational AI bots with real-time video using [Pipecat](https://github.com/pipecat-ai/pipecat) and [Tavus](https://www.tavus.io/).

## ğŸ‰ Hackathon Sponsorship

![Tavus Hackathon Sponsor](images/image.png)

**Tavus is proud to be sponsoring this year's hackathon!** We build APIs that let you create video agents, AI humans that can see, hear, and respond face-to-face in real time (and even take actions).

You can use Tavus in two ways:

**Full Pipeline**: Get everything out of the box: WebRTC, real-time ASR, Tavus LLM, and Phoenix, Sparrow, and Raven models for lifelike video. Spin up conversational video agents in minutes.

**Bring Your Own LLM**: Already have a stack? Plug in your LLM or TTS and use Tavus' perception, timing, and avatars for humanlike video conversations.

This repo implements the **Bring Your Own LLM** flow using Daily's Pipecat for real-time media handling and Google Gemini as the LLM backend.

## ğŸ¥ What This Project Does

This project creates a conversational AI assistant that:
- **Listens** to your voice in real-time
- **Understands** what you're saying using speech recognition
- **Thinks** and generates intelligent responses using an LLM
- **Speaks** back with natural-sounding voice
- **Shows** a realistic video avatar (digital replica) speaking your response

All of this happens in real-time over WebRTC with sub-second latency!

## ğŸš€ Quick Start

**Get up and running in 5 minutes!** See **[QUICKSTART.md](QUICKSTART.md)** for detailed step-by-step instructions.

```bash
# 1. Install dependencies
uv sync                          # Backend (Python)
cd frontend && npm install       # Frontend (React)

# 2. Configure API keys in .env file
# (See QUICKSTART.md for where to get keys)

# 3. Run the app (2 terminals)
uv run python tavus-pipecat.py --transport webrtc --host localhost --port 8080
cd frontend && npm start

# 4. Open browser at http://localhost:3000 and start talking!
```

ğŸ‘‰ **[See QUICKSTART.md for detailed instructions, troubleshooting, and API key setup](QUICKSTART.md)**

## ğŸ“ Project Structure

```
tavus-pipecat-quickstart/
â”œâ”€â”€ tavus-pipecat.py              # ğŸ¤– Main bot server implementation
â”‚                                  #    - Initializes AI services
â”‚                                  #    - Creates processing pipeline
â”‚                                  #    - Handles RTVI protocol
â”‚
â”œâ”€â”€ pyproject.toml                # ğŸ“¦ Python dependencies (uv format)
â”œâ”€â”€ requirements.txt              # ğŸ“¦ Legacy requirements (pip format)
â”œâ”€â”€ .env                          # ğŸ”‘ API keys (you create this)
â”‚
â”œâ”€â”€ frontend/                     # âš›ï¸ React web application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ webrtc-client.js      # ğŸ“¡ RTVI WebRTC client wrapper
â”‚   â”‚   â”‚                          #    - Connects to bot server
â”‚   â”‚   â”‚                          #    - Handles media streams
â”‚   â”‚   â”‚                          #    - Manages RTVI protocol
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â””â”€â”€ VideoConversation.js  # ğŸ¬ Main UI component
â”‚   â”‚                                  #    - Video display
â”‚   â”‚                                  #    - Controls (mute, camera)
â”‚   â”‚                                  #    - Connection status
â”‚   â”‚
â”‚   â””â”€â”€ package.json              # ğŸ“¦ Frontend dependencies
â”‚
â”œâ”€â”€ QUICKSTART.md                 # ğŸ“– Detailed setup guide
â””â”€â”€ README.md                     # ğŸ“– This file
```

## ğŸ”§ How It Works

**High-Level Flow:**

```
You speak â†’ ğŸ¤ Deepgram (STT) â†’ ğŸ§  Gemini (LLM) â†’ ğŸ—£ï¸ Cartesia (TTS) â†’ ğŸ¥ Tavus (Video) â†’ Bot responds
```

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend  â”‚  â† User's browser (camera/mic)
â”‚   RTVI Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ WebRTC Connection
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python Backend   â”‚  â† Pipecat server
â”‚  Processing      â”‚     â€¢ Speech-to-Text (Deepgram)
â”‚  Pipeline        â”‚     â€¢ LLM Generation (Gemini)
â”‚                  â”‚     â€¢ Text-to-Speech (Cartesia)
â”‚                  â”‚     â€¢ Video Generation (Tavus)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

All processing happens in **real-time** with **sub-second latency** using the **RTVI protocol** for perfect client-server coordination.

## ğŸ› ï¸ Technologies

### Backend (Python)
- **Pipecat Framework**: Voice AI pipeline orchestration
- **Deepgram**: Real-time speech-to-text
- **Cartesia**: High-quality text-to-speech
- **Google Gemini**: Large language model
- **Tavus**: AI video replica generation
- **WebRTC**: Real-time communication

### Frontend (JavaScript/React)
- **React**: UI framework
- **Pipecat RTVI SDK** (`@pipecat-ai/client-js`): RTVI protocol client
- **Small WebRTC Transport**: Lightweight WebRTC implementation

## ğŸ¨ Customization

All the code is easily customizable:

- **Bot personality**: Edit system prompt in `tavus-pipecat.py`
- **Voice**: Change Cartesia `voice_id`
- **Video quality**: Adjust resolution settings
- **LLM provider**: Swap Gemini for OpenAI, Anthropic, etc.
- **UI**: Customize React components in `frontend/src/`

See [QUICKSTART.md](QUICKSTART.md#next-steps) for detailed customization examples.

## ğŸ“š Learn More

- **[QUICKSTART.md](QUICKSTART.md)** - Complete setup guide with troubleshooting
- **[Pipecat Docs](https://docs.pipecat.ai/)** - Framework documentation
- **[Pipecat Examples](https://github.com/pipecat-ai/pipecat-examples)** - More example projects
- **[Pipecat Discord](https://discord.gg/pipecat)** - Community support

## ğŸ“„ License

See LICENSE file for details.
